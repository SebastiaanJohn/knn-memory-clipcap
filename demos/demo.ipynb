{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo notebook\n",
    "## kNN-Memory with ClipCap: Enhanced Long-Range Dependency Handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to ClipMemClap's interactive notebook! Here, you can upload your own .mp4 clip and our system will generate a customized caption for your clip.\n",
    "\n",
    "To ensure a smooth operation, please adhere to the following steps:\n",
    "\n",
    "- Ensure that your current location is within the ./knn-memory-clipcap/demos directory. You can access this directory by following this link: SebastiaanJohn's knn-memory-clipcap Github repository.\n",
    "- Make sure that your video file is in the same directory as this notebook.\n",
    "\n",
    "Once you upload your video, the following processes will occur:\n",
    "\n",
    "- A folder named 'frames' will be automatically generated within this directory, which will serve as the storage for the frames extracted from your video.\n",
    "- Another folder, titled 'embeddings', will be created. This is where the CLIP embeddings of the frames will be stored.\n",
    "\n",
    "If you prefer for the 'embeddings' and 'frames' folders to be deleted after the captioning process, you can set the variable rem_dirs to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import wget\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path_2 = os.path.abspath(os.path.join(\"../src\"))\n",
    "if module_path_2 not in sys.path:\n",
    "    sys.path.append(module_path_2)\n",
    "\n",
    "from src.models.clipcap import ClipCaptionPrefix\n",
    "from src.predict import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download a model as follows, where the argument specifies the directory where the model will be downloaded to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the link provided here is just one example that can be used\n",
    "# !wget \"https://drive.google.com/u/0/uc?id=1vYAhRGVMiFmS9D3NdOx16Hf0Nhdr_hoJ&export=download&confirm=t\" -O ../checkpoints/model.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This location is dedicated to storing the specific model you've chosen for the caption generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"../checkpoints/model.pt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please input the name of your video, ensuring it includes the .mp4 extension. The individual frames from your video will be saved in the 'frames' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for video: tennis.mp4\n",
      "Succesfully dumped frames of tennis: 101 frames\n"
     ]
    }
   ],
   "source": [
    "video_name = \"tennis.mp4\"\n",
    "extract_frames(video_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the video for which the system will generate a corresponding caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"tennis.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(video_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the trained ClipMemCap model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arguments need to match those of the saved model\n",
    "model = ClipCaptionPrefix(\n",
    "    10,\n",
    "    batch_size=1,\n",
    "    clip_length=10,\n",
    "    prefix_size=512,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    memorizing_layers=(4, 5),\n",
    "    max_knn_memories=64000,\n",
    "    num_retrieved_memories=32,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_DIR, map_location=\"cpu\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the caption!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Creating CLIP embeddings of frames...: 100%|██████████| 101/101 [00:09<00:00, 10.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 253.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
      "100%|██████████| 101/101 [00:00<00:00, 349813.96it/s]\n",
      "Generating caption...: 100%|██████████| 101/101 [00:10<00:00, 10.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A man is standing in the middle of the field.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_caption(video_name, model, remove_dirs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
