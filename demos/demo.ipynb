{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook\n",
    "### kNN-Memory with ClipCap: Enhanced Long-Range Dependency Handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook where you can submit your own mp4 clip, after which ClipMemClap will generate a caption for the clip! \n",
    "\n",
    "For this to work, please:\n",
    "- make sure you currently are in the ./knn-memoroy-clipcap/demos directory (https://github.com/SebastiaanJohn/knn-memory-clipcap/tree/main/demos).\n",
    "- have the video in the same directory as this notebook.\n",
    "\n",
    "Parsing a video will cause a folder named 'frames' to be created in this directory, where the frames of the submitted videos will be stored. \\\n",
    "Also, a folder named 'embeddings' will be created, where the CLIP embeddings of the frames will be stored. \\\n",
    "If you would like the 'embeddings' and 'frames' folders to be removed after the caption has been made, set _rem_dirs_ to _True_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path_2 = os.path.abspath(os.path.join('../src'))\n",
    "if module_path_2 not in sys.path:\n",
    "    sys.path.append(module_path_2)\n",
    "\n",
    "from src.models.clipcap import ClipCaptionPrefix\n",
    "from src.process_vid import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is where the model that you want to use for the captioning is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../checkpoints/activitynet_with_mem-best.pt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please provide the name of the video, including the .mp4 suffix.\n",
    "The frames of the video will be stored in the 'frames' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for video: tennis.mp4\n",
      "Succesfully dumped frames of tennis: 101 frames\n"
     ]
    }
   ],
   "source": [
    "video_name = 'tennis.mp4'\n",
    "extract_frames(video_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video for which the caption will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"tennis.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(video_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the trained ClipMemCap model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arguments need to match those of the saved model\n",
    "model = ClipCaptionPrefix(\n",
    "            10,\n",
    "            batch_size = 1,\n",
    "            clip_length= 10,\n",
    "            prefix_size= 512,\n",
    "            num_layers= 8,\n",
    "            num_heads = 8,\n",
    "            memorizing_layers = (4,5),\n",
    "            max_knn_memories = 64000,\n",
    "            num_retrieved_memories = 32\n",
    "        )\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_DIR, map_location=\"cpu\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the caption!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CLIP embeddings of frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1238.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 21845.33it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 594334.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating caption...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A man is playing a tennis racket on a tennis court.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_caption(video_name, model, remove_dirs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
